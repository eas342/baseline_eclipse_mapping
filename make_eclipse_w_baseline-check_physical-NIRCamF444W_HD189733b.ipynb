{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eclipse Mapping while Checking if Physical (non-negative maps)\n",
    "# More realistic NIRCam Sim\n",
    "Uses standard deviation from mirage simulation at expected real cadence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import starry\n",
    "from copy import deepcopy\n",
    "import astropy.units as u\n",
    "import astropy.constants as const\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits, ascii\n",
    "from corner import corner\n",
    "import os\n",
    "\n",
    "starry.config.lazy = False\n",
    "starry.config.quiet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starry.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Forward Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Earth map as an example map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ell = 3\n",
    "\n",
    "up_bin = 10 ## up-bin for clarity\n",
    "lc_precision = 145e-6 / np.sqrt(up_bin) ## measured from broadband F444W precision\n",
    "cadence = 2.72486 * up_bin ## between exposures\n",
    "npoints = int(np.round(0.2 * 24. * 3600.  / (cadence))) ## duration/cadence\n",
    "extra_descrip = '_check_physical_nc_f444w'\n",
    "\n",
    "map1 = starry.Map(max_ell)\n",
    "\n",
    "map1.load(\"earth\", sigma=0.05)\n",
    "y_input = deepcopy(map1.y[1:])\n",
    "map1.show(projection=\"rect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "map1.show(projection='ortho',ax=ax)\n",
    "fig.savefig('plots/forward_model/forward_map{}.png'.format(extra_descrip),dpi=150,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a lightcurve for HD 189733 with this map.\n",
    "\n",
    "Start by reading in a model for the depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDat = ascii.read('sim_data/hd189733b_spec_model_binned.csv')\n",
    "modelDat[1]['depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_star = 0.812 ## Addison et al. 2019, solar masses\n",
    "R_star = 0.765 ## Addison et al. 2019, solar radii\n",
    "inc=85.69 ## Addison et al. 2019\n",
    "#inc=90.0\n",
    "rp = 0.1504 * R_star ## Addison et al. 2019, Solar radii\n",
    "P_b = 2.218577 ## days\n",
    "log_amp = np.log10(modelDat[1]['depth'])\n",
    "t0 = 0.0\n",
    "\n",
    "M_planet = (1.166 * u.Mjup).to(u.Msun).value ## Addison et al. 2019, Solar masses\n",
    "\n",
    "prot_star = 1.0\n",
    "\n",
    "x = np.linspace(0.5 * P_b - 0.1,0.5 * P_b + 0.1,npoints)\n",
    "#x = np.linspace(0.,P_b,4096)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the impact parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norb = 2. * np.pi / (P_b * u.day)\n",
    "a_orb = (const.G * (M_star * u.Msun) / norb**2)**(1./3.)\n",
    "a_over_r_star = (a_orb/(R_star * u.Rsun)).si\n",
    "b_impact = a_over_r_star * np.cos(inc * np.pi/180.)\n",
    "b_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_orb.to(u.AU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_over_r_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_table = Table()\n",
    "y_labels1, y_values1 = [], []\n",
    "for one_l in np.arange(max_ell)+1:\n",
    "    counter=1\n",
    "    print(\"Y_{},m=[\".format(one_l))\n",
    "    for one_m in np.arange(-one_l,one_l+1):\n",
    "        y_labels1.append(\"$Y_{{{},{}}}$\".format(one_l,one_m))\n",
    "        print(\"Y_{}_{} = {}\".format(one_l,one_m,y_input[counter]))\n",
    "        #print(y_input[counter])\n",
    "        counter = counter + 1\n",
    "    print(\"] \\n\")\n",
    "y_table['label'] = y_labels1\n",
    "y_table['value'] = np.round(y_input,4)\n",
    "y_table['res'] = '\\\\nodata'\n",
    "y_table.write('plots/forward_model/forward_mod.tex',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the transit durations for contacts 1 to 4 and 2 to 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = np.sqrt((1. + rp/R_star)**2 - b_impact**2)/ (a_over_r_star * np.sin(inc * np.pi/180.))\n",
    "Tdur_14 = (P_b / np.pi) * np.arcsin(arg)\n",
    "Thalf_14 = (0.5 * Tdur_14).value\n",
    "\n",
    "arg2 = np.sqrt((1. - rp/R_star)**2 - b_impact**2)/ (a_over_r_star * np.sin(inc * np.pi/180.))\n",
    "Tdur_23 = (P_b / np.pi) * np.arcsin(arg2)\n",
    "Thalf_23 = (0.5 * Tdur_23).value\n",
    "Thalf_14,Thalf_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = starry.Primary(starry.Map(ydeg=0, udeg=2, amp=1.0), m=M_star, r=R_star,\n",
    "                   prot=prot_star )\n",
    "b = starry.kepler.Secondary(map1,\n",
    "                            m=M_planet,r=rp,prot=P_b,porb=P_b,t0=t0,inc=inc)\n",
    "b.map.amp = 10**log_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.theta0 = 180.0 + 0.0\n",
    "sys = starry.System(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_w_data(x,model,data,yerr,ingressZoom=False):\n",
    "    if ingressZoom == True:\n",
    "        fig, axArr = plt.subplots(1,2,sharey=True,figsize=(9,4))\n",
    "        outName = \"forward_model_lc{}_zoom.pdf\".format(extra_descrip)\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(figsize=(9,4))\n",
    "        axArr = [ax1]\n",
    "        outName = \"forward_model_lc{}.pdf\".format(extra_descrip)\n",
    "        \n",
    "    for i,ax in enumerate(axArr):\n",
    "        ax.set_xlabel(\"Time (days)\")\n",
    "        if i==0:\n",
    "            ax.set_ylabel(\"Normalized Flux\")\n",
    "        ax.errorbar(x,ysim,yerr=yerr,fmt='.',zorder=0)\n",
    "        ax.plot(x,flux_input,zorder=2)\n",
    "\n",
    "        \n",
    "        if ingressZoom == True:\n",
    "            #ax.set_xlim(0.5 * P_b - Thalf_14,0.5 * P_b - Thalf_23)\n",
    "            t_ing = Thalf_14 - Thalf_23\n",
    "            t1 = Thalf_14 + t_ing * 0.2\n",
    "            t2 = Thalf_23 - t_ing * 0.2\n",
    "            #t1, t2 = 0.044, 0.0325\n",
    "            if i==0:\n",
    "                \n",
    "                ax.set_xlim(0.5 * P_b - t1,0.5 * P_b -t2)\n",
    "            else:\n",
    "                ax.set_xlim(0.5 * P_b + t2,0.5 * P_b + t1)\n",
    "    savePath = os.path.join('plots','forward_model',outName)\n",
    "    fig.savefig(savePath)\n",
    "                \n",
    "flux_input = deepcopy(sys.flux(x))\n",
    "\n",
    "np.random.seed(0)\n",
    "yerr = np.ones_like(x) * lc_precision\n",
    "ysim = flux_input + np.random.randn(len(x)) * yerr\n",
    "\n",
    "plot_model_w_data(x,flux_input,ysim,yerr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_w_data(x,flux_input,ysim,yerr,ingressZoom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_info(A):\n",
    "    \"\"\"Compute some information about the null space of the design matrix A.\"\"\"\n",
    "    # Get the Fisher information & compute its rank\n",
    "    I = A.T.dot(A)\n",
    "    R = np.linalg.matrix_rank(I)\n",
    "\n",
    "    # Number of coefficientss\n",
    "    C = I.shape[0]\n",
    "\n",
    "    # Size of null space\n",
    "    N = C - R\n",
    "\n",
    "    # Fractional size of null space\n",
    "    F = N / C\n",
    "\n",
    "    # Show it graphically\n",
    "    fig, ax = plt.subplots(figsize=(6, 0.3))\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.axvspan(0, 1 - F, color=\"C0\")\n",
    "    ax.axvspan(1 - F, 1, color=\"red\")\n",
    "    ax.annotate(\n",
    "        \"{}/{}\".format(R, C),\n",
    "        color=\"C0\",\n",
    "        fontsize=10,\n",
    "        xy=(-0.025, 0.5),\n",
    "        xycoords=\"axes fraction\",\n",
    "        va=\"center\",\n",
    "        ha=\"right\",\n",
    "    )\n",
    "    ax.annotate(\n",
    "        \"{:.0f}%\".format(100 * F),\n",
    "        color=\"w\",\n",
    "        fontsize=10,\n",
    "        xy=(1 - 0.5 * F, 0.5),\n",
    "        xycoords=\"axes fraction\",\n",
    "        va=\"center\",\n",
    "        ha=\"right\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the nullspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sys.design_matrix(x)\n",
    "compute_info(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(6):#sec.map.Ny):\n",
    "    plt.plot(A[:,i] - 0.6 * i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For degree=4 there's a pretty small nullspace, but still some coefficints are unconstrained. For degree=3 I don't see any nullspace which is pretty cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve the Linear System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior on primary\n",
    "# pri_mu = np.zeros(sys.primary.map.Ny)\n",
    "# pri_mu[0] = 1.0\n",
    "# pri_L = np.zeros(pri.map.Ny)\n",
    "# pri_L[0] = 1e-2\n",
    "# pri_L[1:] = 1e-2\n",
    "# pri.map.set_prior(mu=pri_mu, L=pri_L)\n",
    "\n",
    "# Prior on the planet = secondary\n",
    "sec = sys.secondaries[0]\n",
    "sec_mu = np.zeros(sec.map.Ny)\n",
    "sec_mu[0] = 1e-3\n",
    "## sec_mu[1:] = y_input * sec_mu[0]## what if we cheat at start them at the correct values? Just to check \n",
    "## that it can recover\n",
    "sec_L = np.zeros(sec.map.Ny)\n",
    "sec_L[0] = (0.2 * sec_mu[0])**2 ## covariance is squared\n",
    "#sec_L[1:] = (1e-8)**2\n",
    "#sec_L[1:] = (1.0 * sec_mu[0])**2 ## THIS GIVES MOSTLY UNPHYSICAL (negative)\n",
    "sec_L[1:] = (0.15 * sec_mu[0])**2 ### THIS GIVES MOSTLY PHYSICAL MAPS (>=0)\n",
    "\n",
    "sec.map.set_prior(mu=sec_mu, L=sec_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.set_data(ysim, C=yerr**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, cho_cov = sys.solve(t=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec.map.amp = mu[0]\n",
    "sec.map[1:, :] = mu[1:] / sec.map.amp\n",
    "sys.secondaries[0].map = sec.map\n",
    "\n",
    "plot_model_w_data(x,sys.flux(x),ysim,yerr,ingressZoom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_w_data(x,sys.flux(x),ysim,yerr,ingressZoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the amplitudes\n",
    "The solution given gives the Cholesky decomposition of the covariance matrix (not the actual covariance matrix). I think this is how you get the covariance matrix. You can also skip down to the corner plot, where it looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.dot(cho_cov,cho_cov.T)\n",
    "np.sqrt(np.diag(cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the amplitudes and spherical harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10**log_amp, mu[0], np.sqrt(cov[0,0]))\n",
    "\n",
    "mu[1:]/mu[0]\n",
    "\n",
    "coeff_ind = np.arange(len(y_input)) + 1\n",
    "coeff_mean = mu[1:]/mu[0]\n",
    "coeff_err = np.sqrt(np.diag(cov))/mu[0]\n",
    "\n",
    "coeff_labels = [r\"$Y_{%d,%d}$\" % (l, m)\n",
    "    for l in range(1, sec.map.ydeg + 1)\n",
    "    for m in range(-l, l + 1)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(coeff_ind,y_input,label='Input Forward Model')\n",
    "ax.errorbar(coeff_ind,coeff_mean,yerr=coeff_err[1:],label='Posterior Mean')\n",
    "ax.set_xlabel(\"Coefficient index\")\n",
    "ax.set_ylabel(\"$C_{l}^m$\")\n",
    "ax.legend()\n",
    "\n",
    "for ind,oneLabel in enumerate(coeff_labels):\n",
    "    ax.text(coeff_ind[ind] - 0.3,-0.1 + np.mod(ind,2) * 0.2,oneLabel)\n",
    "fig.savefig('plots/linear_results/coeff_results_linear_fit{}.pdf'.format(extra_descrip))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Input Map - Dayside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = sys.secondaries[0]\n",
    "sec.map.amp = 10**log_amp\n",
    "sec.map.y[1:] = y_input\n",
    "#sec.map.show(projection='rect')\n",
    "sec.map.show(projection='ortho',theta=0.0)\n",
    "#sec.map.show(theta=180.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm that this is the dayside by visualizing the whole system\n",
    "#sys.show(0.46 * P_b,figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean values\n",
    "sec = sys.secondaries[0]\n",
    "\n",
    "# sec.map.amp = mu[0]\n",
    "# ## The tutorial notebook divides mu by amp, but it didn't look correct\n",
    "# sec.map[1:, :] = mu[1 : sec.map.Ny]  #/ sec.map.amp\n",
    "\n",
    "sec.map.amp = mu[0]\n",
    "sec.map[1:, :] = mu[1:] / sec.map.amp\n",
    "\n",
    "sec.map.show(projection=\"ortho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sec.map.render(projection='rect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(res), np.min(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec.map.y[1:], y_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.secondaries[0].map = sec.map\n",
    "yfit = sys.flux(x)\n",
    "resid = yfit - ysim\n",
    "\n",
    "fig, (ax,ax2) = plt.subplots(2,sharex=True)\n",
    "ax.plot(x,yfit)\n",
    "ax.errorbar(x,ysim,alpha=0.5)\n",
    "ax2.plot(x,resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare a few draws with the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "for i in np.arange(5):\n",
    "    sys.draw()\n",
    "    sys.secondaries[0].map.show(projection='ortho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = np.append(10**log_amp,y_input[:8])\n",
    "\n",
    "nsamples = 10000\n",
    "u = np.random.randn(len(mu), nsamples)\n",
    "samples = mu.reshape(1, -1) + np.dot(cho_cov, u).T\n",
    "\n",
    "# De-weight the samples to get\n",
    "# samples of the actual Ylm coeffs\n",
    "samps = np.array(samples[:, :9])\n",
    "samps[:, 1:] /= samps[:, 0].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9, 9, figsize=(12, 12))\n",
    "labels = [r\"$\\alpha$\"] + [\n",
    "    r\"$Y_{%d,%d}$\" % (l, m)\n",
    "    for l in range(1, sec.map.ydeg + 1)\n",
    "    for m in range(-l, l + 1)\n",
    "]\n",
    "\n",
    "corner(samps, fig=fig, labels=labels,truths=truths)\n",
    "for axis in ax.flatten():\n",
    "    axis.xaxis.set_tick_params(labelsize=6)\n",
    "    axis.yaxis.set_tick_params(labelsize=6)\n",
    "    axis.xaxis.label.set_size(12)\n",
    "    axis.yaxis.label.set_size(12)\n",
    "    axis.xaxis.set_label_coords(0.5, -0.6)\n",
    "    axis.yaxis.set_label_coords(-0.6, 0.5)\n",
    "fig.savefig('plots/corner/Flat_001_maptype_variable_amp_type_variableFlat{}.png'.format(extra_descrip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure Physical Results\n",
    "Check what fraction of the samples are physical (non-negative flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = nsamples\n",
    "map_mins = []\n",
    "sec_map = sys.secondaries[0].map\n",
    "for i in np.arange(n_samples):\n",
    "    #sys.draw()\n",
    "    #sys.secondaries[0].map.y[1:] = samples[i,1:]\n",
    "    sec_map.amp = samples[i,0]\n",
    "    sec_map.y[1:] = samples[i,1:] / samples[i,0]\n",
    "    map_evaluate = sec_map.render(projection='rect',res=100)\n",
    "    map_mins.append(np.min(map_evaluate))\n",
    "\n",
    "pos_maps = np.array(map_mins) > 0\n",
    "n_pos = np.sum(pos_maps)\n",
    "print(\"{} out of {} are positive\".format(n_pos,n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how much better the precision is on these coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples = samples[pos_maps,:]\n",
    "\n",
    "good_coeff = good_samples[:,1:] / np.tile(good_samples[:,0],[len(coeff_ind),1]).T\n",
    "mean_good = np.mean(good_coeff,axis=0)\n",
    "median_good = np.median(good_coeff,axis=0)\n",
    "stdev_good = np.std(good_coeff,axis=0)\n",
    "#    sec_map.y[1:] = good_samples[i,1:] / good_samples[i,0]\n",
    "#coeff_mean_new = np.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(coeff_ind,y_input,label='Input Forward Model')\n",
    "ax.errorbar(coeff_ind,coeff_mean,yerr=coeff_err[1:],label='Posterior Mean, All',capsize=3)\n",
    "ax.errorbar(coeff_ind,median_good,yerr=stdev_good,label='Posterior Mean, Physical',capsize=3)\n",
    "ax.set_xlabel(\"Coefficient index\")\n",
    "ax.set_ylabel(\"$C_{l}^m$\")\n",
    "ax.legend()\n",
    "\n",
    "for ind,oneLabel in enumerate(coeff_labels):\n",
    "    ax.text(coeff_ind[ind] - 0.3,-0.2 + np.mod(ind,2) * 0.2,oneLabel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except for $Y_{1,0}$, this looks way better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the maps that are positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nshow = 4\n",
    "sec_map = sys.secondaries[0].map\n",
    "\n",
    "for i in np.arange(nshow):\n",
    "    sec_map.amp = good_samples[i,0]\n",
    "    sec_map.y[1:] = good_samples[i,1:] / good_samples[i,0]\n",
    "    sec_map.show(projection='ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are much closer to the input map!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a quadratic (2nd order) Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = (x - np.mean(x))/(0.5 * (np.max(x) - np.min(x)))\n",
    "c = np.array([2e-4,3e-4,1.]) ## backwards order c_0 x^n + c_(1) x^(n-1) + ... c_(n-2) x^2 + c_(n-1) x + 1\n",
    "baseline = np.polyval(c,x_norm)\n",
    "\n",
    "bsim = ysim * baseline\n",
    "\n",
    "plt.plot(x,bsim)\n",
    "plt.xlabel('Time (JD)')\n",
    "plt.ylabel(\"Normalized Flux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outTable = Table()\n",
    "outTable['Time (days)'] = x\n",
    "outTable['Flux'] = bsim\n",
    "outTable['Flux err'] = yerr\n",
    "outTable['Flux before Baseline'] = ysim\n",
    "outTable['Baseline'] = baseline\n",
    "meta1 = {'Amplitude':10**log_amp,\n",
    "         'Period':P_b,\n",
    "         'Period_units': 'days',\n",
    "         'M_star': M_star,\n",
    "         'M_star_units': 'Msun',\n",
    "         'R_star': R_star,\n",
    "         'M_planet': M_planet,\n",
    "         'M_planet_units': 'Msun',\n",
    "         'inc': inc,\n",
    "         'inc_units': 'deg',\n",
    "         'rp': rp,\n",
    "         'rp_units': 'Rsun',\n",
    "         't0': t0,\n",
    "         'y_input': list(y_input),\n",
    "         'baseline_c': list(c),\n",
    "         'dur_14': Thalf_14 * 2.,\n",
    "         'dur_23': Thalf_23 * 2.,\n",
    "         'b_impact': b_impact,\n",
    "         'prot_star': prot_star}\n",
    "outTable.meta = meta1\n",
    "outTable.write('sim_data/sim_data_baseline_hd189_ncF444W.ecsv',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the noiseless and noisy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,sharex=True)\n",
    "ax.plot(x,flux_input,label='Noiseless Model',zorder=2,linewidth=2,color='black')\n",
    "ax.plot(x,ysim,'.',label='Simulated Data: Flat Baseline',zorder=1,color='green')\n",
    "ax.plot(x,bsim,'.',label='Simulated Data: Baseline Trend',zorder=1,color='red')\n",
    "ax.set_ylabel(\"Normalized Flux\")\n",
    "ax.set_xlabel(\"Time (days)\")\n",
    "ax.legend()\n",
    "fig.savefig('plots/forward_model/forward_model_w_baseline_hd189_f444w.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
